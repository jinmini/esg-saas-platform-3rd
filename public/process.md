```
# ESG PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
# Unstructured.ioë¥¼ í™œìš©í•œ ì§€ì†ê°€ëŠ¥ê²½ì˜ë³´ê³ ì„œ ìë™ íŒŒì‹±

import os
import json
from pathlib import Path
from typing import List, Dict, Any
from unstructured.partition.pdf import partition_pdf
from unstructured.chunking.title import chunk_by_title
from unstructured.staging.base import elements_to_json
import time

class ESGDocumentProcessor:
    """ESG ë¬¸ì„œ ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir: str = "processed_docs"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
    def process_pdf(self, pdf_path: str, use_ocr: bool = False) -> List[Dict]:
        """
        PDF ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ì—¬ êµ¬ì¡°í™”ëœ ìš”ì†Œë“¤ì„ ì¶”ì¶œ
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            use_ocr: OCR ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        
        Returns:
            List[Dict]: ì¶”ì¶œëœ ë¬¸ì„œ ìš”ì†Œë“¤
        """
        print(f"ğŸ“„ PDF ì²˜ë¦¬ ì‹œì‘: {pdf_path}")
        start_time = time.time()
        
        try:
            # Unstructuredë¡œ PDF íŒŒí‹°ì…”ë‹
            elements = partition_pdf(
                filename=pdf_path,
                strategy="fast",  # "fast", "hi_res", "ocr_only" ì˜µì…˜
                infer_table_structure=True,  # í…Œì´ë¸” êµ¬ì¡° ì¸ì‹
                include_page_breaks=True,    # í˜ì´ì§€ êµ¬ë¶„ í¬í•¨
                extract_images_in_pdf=False, # ì´ë¯¸ì§€ ì¶”ì¶œ (ìš©ëŸ‰ ì ˆì•½ì„ ìœ„í•´ False)
                chunking_strategy="by_title" # ì œëª©ë³„ ì²­í‚¹
            )
            
            print(f"âœ… ì´ {len(elements)}ê°œ ìš”ì†Œ ì¶”ì¶œ ì™„ë£Œ")
            print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")
            
            return elements
            
        except Exception as e:
            print(f"âŒ PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []
    
    def analyze_document_structure(self, elements: List) -> Dict[str, Any]:
        """ë¬¸ì„œ êµ¬ì¡° ë¶„ì„"""
        structure = {
            "total_elements": len(elements),
            "element_types": {},
            "titles": [],
            "tables": [],
            "page_count": 0
        }
        
        for element in elements:
            # ìš”ì†Œ íƒ€ì…ë³„ ì¹´ìš´íŠ¸
            element_type = str(type(element).__name__)
            structure["element_types"][element_type] = structure["element_types"].get(element_type, 0) + 1
            
            # ì œëª© ìš”ì†Œ ìˆ˜ì§‘
            if hasattr(element, 'category') and element.category == "Title":
                structure["titles"].append(element.text)
            
            # í…Œì´ë¸” ìš”ì†Œ ìˆ˜ì§‘
            if hasattr(element, 'category') and element.category == "Table":
                structure["tables"].append(element.text[:200] + "..." if len(element.text) > 200 else element.text)
            
            # í˜ì´ì§€ ìˆ˜ ê³„ì‚°
            if hasattr(element, 'metadata') and element.metadata.page_number:
                structure["page_count"] = max(structure["page_count"], element.metadata.page_number)
        
        return structure
    
    def extract_esg_keywords(self, elements: List) -> Dict[str, List[str]]:
        """ESG ê´€ë ¨ í‚¤ì›Œë“œ ë° ë‚´ìš© ì¶”ì¶œ"""
        esg_keywords = {
            "í™˜ê²½(E)": ["ì˜¨ì‹¤ê°€ìŠ¤", "íƒ„ì†Œë°°ì¶œ", "ì—ë„ˆì§€", "ì¬ìƒì—ë„ˆì§€", "í™˜ê²½ê²½ì˜", "ê¸°í›„ë³€í™”", "íƒ„ì†Œì¤‘ë¦½"],
            "ì‚¬íšŒ(S)": ["ì•ˆì „", "ì§ì›", "ë‹¤ì–‘ì„±", "ì§€ì—­ì‚¬íšŒ", "ì¸ê¶Œ", "ê³ ìš©", "ë³µì§€", "êµìœ¡"],
            "ì§€ë°°êµ¬ì¡°(G)": ["ì´ì‚¬íšŒ", "ìœ¤ë¦¬", "ì»´í”Œë¼ì´ì–¸ìŠ¤", "íˆ¬ëª…ì„±", "ê°ì‚¬", "ìœ„í—˜ê´€ë¦¬", "ì§€ë°°êµ¬ì¡°"]
        }
        
        extracted_content = {category: [] for category in esg_keywords.keys()}
        
        for element in elements:
            element_text = element.text if hasattr(element, 'text') else str(element)
            
            for category, keywords in esg_keywords.items():
                for keyword in keywords:
                    if keyword in element_text:
                        # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ë‹¨ ì „ì²´ ì €ì¥ (ìµœëŒ€ 500ì)
                        content = element_text[:500] + "..." if len(element_text) > 500 else element_text
                        if content not in extracted_content[category]:
                            extracted_content[category].append(content)
        
        return extracted_content
    
    def save_results(self, elements: List, structure: Dict, esg_content: Dict, filename: str):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        
        # 1. ì „ì²´ ìš”ì†Œë¥¼ JSONìœ¼ë¡œ ì €ì¥
        elements_json = elements_to_json(elements)
        with open(self.output_dir / f"{filename}_elements.json", "w", encoding="utf-8") as f:
            json.dump(elements_json, f, ensure_ascii=False, indent=2)
        
        # 2. êµ¬ì¡° ë¶„ì„ ê²°ê³¼ ì €ì¥
        with open(self.output_dir / f"{filename}_structure.json", "w", encoding="utf-8") as f:
            json.dump(structure, f, ensure_ascii=False, indent=2)
        
        # 3. ESG ë‚´ìš© ì €ì¥
        with open(self.output_dir / f"{filename}_esg_content.json", "w", encoding="utf-8") as f:
            json.dump(esg_content, f, ensure_ascii=False, indent=2)
        
        # 4. ìš”ì•½ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
        with open(self.output_dir / f"{filename}_summary.txt", "w", encoding="utf-8") as f:
            f.write("=" * 50 + "\n")
            f.write("ESG ë¬¸ì„œ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"ğŸ“Š ë¬¸ì„œ êµ¬ì¡°:\n")
            f.write(f"- ì „ì²´ ìš”ì†Œ ìˆ˜: {structure['total_elements']}ê°œ\n")
            f.write(f"- í˜ì´ì§€ ìˆ˜: {structure['page_count']}í˜ì´ì§€\n")
            f.write(f"- ì œëª© ìˆ˜: {len(structure['titles'])}ê°œ\n")
            f.write(f"- í…Œì´ë¸” ìˆ˜: {len(structure['tables'])}ê°œ\n\n")
            
            f.write("ğŸ“‹ ìš”ì†Œ íƒ€ì…ë³„ ë¶„í¬:\n")
            for elem_type, count in structure['element_types'].items():
                f.write(f"- {elem_type}: {count}ê°œ\n")
            f.write("\n")
            
            f.write("ğŸ¯ ì£¼ìš” ì œëª©ë“¤:\n")
            for i, title in enumerate(structure['titles'][:10], 1):
                f.write(f"{i}. {title}\n")
            f.write("\n")
            
            f.write("ğŸ” ESG ê´€ë ¨ ë‚´ìš© ì¶”ì¶œ:\n")
            for category, contents in esg_content.items():
                f.write(f"\n[{category}] - {len(contents)}ê±´ ë°œê²¬:\n")
                for i, content in enumerate(contents[:3], 1):  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                    f.write(f"{i}. {content[:100]}...\n")
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {self.output_dir}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ESG PDF ì²˜ë¦¬ê¸° ì‹œì‘")
    print("=" * 50)
    
    # PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
    pdf_path = "esg.pdf"  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”
    
    # PDF íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(pdf_path):
        print(f"âŒ ì˜¤ë¥˜: '{pdf_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ“ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:")
        print("   1. 'esg.pdf' íŒŒì¼ì„ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ë³µì‚¬")
        print("   2. ì•„ë˜ ì½”ë“œì—ì„œ pdf_path ë³€ìˆ˜ë¥¼ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½")
        return
    
    # ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    processor = ESGDocumentProcessor()
    
    try:
        # 1. PDF ë¬¸ì„œ ì²˜ë¦¬
        elements = processor.process_pdf(pdf_path)
        
        if not elements:
            print("âŒ ë¬¸ì„œ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # 2. ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
        print("\nğŸ“Š ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì¤‘...")
        structure = processor.analyze_document_structure(elements)
        
        # 3. ESG ë‚´ìš© ì¶”ì¶œ
        print("ğŸ” ESG ê´€ë ¨ ë‚´ìš© ì¶”ì¶œ ì¤‘...")
        esg_content = processor.extract_esg_keywords(elements)
        
        # 4. ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 50)
        print("ğŸ“‹ ì²˜ë¦¬ ê²°ê³¼")
        print("=" * 50)
        print(f"ğŸ“„ ì´ ìš”ì†Œ ìˆ˜: {structure['total_elements']}ê°œ")
        print(f"ğŸ“„ í˜ì´ì§€ ìˆ˜: {structure['page_count']}í˜ì´ì§€")
        print(f"ğŸ“„ ì œëª© ìˆ˜: {len(structure['titles'])}ê°œ")
        print(f"ğŸ“„ í…Œì´ë¸” ìˆ˜: {len(structure['tables'])}ê°œ")
        
        print(f"\nğŸ“Š ìš”ì†Œ íƒ€ì…ë³„ ë¶„í¬:")
        for elem_type, count in structure['element_types'].items():
            print(f"  - {elem_type}: {count}ê°œ")
        
        print(f"\nğŸ¯ ì£¼ìš” ì œëª©ë“¤ (ìƒìœ„ 5ê°œ):")
        for i, title in enumerate(structure['titles'][:5], 1):
            print(f"  {i}. {title}")
        
        print(f"\nğŸ” ESG ê´€ë ¨ ë‚´ìš© ë°œê²¬:")
        for category, contents in esg_content.items():
            print(f"  [{category}]: {len(contents)}ê±´")
        
        # 5. ê²°ê³¼ ì €ì¥
        filename = Path(pdf_path).stem
        processor.save_results(elements, structure, esg_content, filename)
        
        print(f"\nâœ… ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤ì„ '{processor.output_dir}' í´ë”ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        
        # 6. Difyìš© ë°ì´í„° ì¤€ë¹„ ì•ˆë‚´
        print(f"\nğŸ”„ ë‹¤ìŒ ë‹¨ê³„: Difyì— ì—…ë¡œë“œ")
        print(f"   - í…ìŠ¤íŠ¸ íŒŒì¼: {processor.output_dir}/{filename}_summary.txt")
        print(f"   - ìƒì„¸ JSON: {processor.output_dir}/{filename}_elements.json")
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   1. PDF íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸")
        print("   2. í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ PDFì¸ì§€ í™•ì¸ (ìŠ¤ìº” ì´ë¯¸ì§€ê°€ ì•„ë‹Œ)")
        print("   3. í•„ìš”ì‹œ OCR ì˜µì…˜ í™œì„±í™”")

if __name__ == "__main__":
    main()
```